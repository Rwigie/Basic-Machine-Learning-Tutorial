{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Part\n",
    "using Numpy and vertor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"toc_40291_2\"></a>\n",
    "# Problem Statement\n",
    "\n",
    "Let's use the same two data points as before - a house with 1000 square feet sold for \\\\$300,000 and a house with 2000 square feet sold for \\\\$500,000.\n",
    "\n",
    "| Size (1000 sqft)     | Price (1000s of dollars) |\n",
    "| ----------------| ------------------------ |\n",
    "| 1               | 300                      |\n",
    "| 2               | 500                      |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Activation Fucntion \n",
    "\n",
    "So far in this course, you have developed a linear model that predicts $f_{w,b}(x^{(i)})$:\n",
    "$$f_{w,b}(x^{(i)}) = wx^{(i)} + b \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_data = np.array([1, 2])     # Size\n",
    "y_data = np.array([300, 500]) # Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data: [1 2]\n",
      "x_data.shape : (2,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_data: {x_data}\")\n",
    "print(f\"x_data.shape : {x_data.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of prediction of y: [0 0]\n"
     ]
    }
   ],
   "source": [
    "def Linear_model(x, w, b):\n",
    "    '''\n",
    "    Input:\n",
    "        w : Integar, representing weight\n",
    "        x : NumpyArray, repersenting Size of the house \n",
    "    Output:\n",
    "        y_hat : NumpyArray, prediction of Price, based on y = w * x\n",
    "    '''  \n",
    "    \n",
    "    f_wb = w * x + b\n",
    "\n",
    "\n",
    "    y_hat = f_wb\n",
    "        \n",
    "    return y_hat\n",
    "\n",
    "# Set initial w value\n",
    "w_init = 0\n",
    "b_init = 0\n",
    "y_hat = Linear_model(x_data, w_init)\n",
    "print(f\"The result of prediction of y: {y_hat}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Cost Function\n",
    "In linear regression, you utilize input training data to fit the parameters $w$,$b$ by minimizing a measure of the error between our predictions $f_{w,b}(x^{(i)})$ and the actual data $y^{(i)}$. The measure is called the $cost$, $J(w,b)$. In training you measure the cost over all of our training samples $x^{(i)},y^{(i)}$\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})^2\\tag{2}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost Function\n",
    "def Cost_function(x, y, w, b):\n",
    "    '''\n",
    "    Input:\n",
    "        w : Integar, representing weight\n",
    "        x : NumpyArray, representing Size of the house \n",
    "        y : NumpyArray, representing Price of the house\n",
    "    Output:\n",
    "        Cost : Int\n",
    "    '''  \n",
    "\n",
    "    N = len(y)\n",
    "    cost = 0\n",
    "    #f_wb = Linear_model(x , w)\n",
    "    \n",
    "    #TODO:\n",
    "    \n",
    "        \n",
    "cost = Cost_function(x_data, y_data, w_init, b_init)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient descent\n",
    "The gradient is defined as:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial J(w,b)}{\\partial w}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)})x^{(i)} \\tag{4}\\\\\n",
    "  \\frac{\\partial J(w,b)}{\\partial b}  &= \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} (f_{w,b}(x^{(i)}) - y^{(i)}) \\tag{5}\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Descent\n",
    "def gradient_function(x, y, w):\n",
    "    '''\n",
    "    Input:\n",
    "        w : Integar, representing weight\n",
    "        x : NumpyArray, representing Size of the house \n",
    "        y : NumpyArray, representing Price of the house\n",
    "    Output:\n",
    "        dj_dw : Float\n",
    "        dj_db : Float\n",
    "    '''  \n",
    "    N = len(x)\n",
    "    dj_dw = 0.0\n",
    "    dj_db = 0.0\n",
    "\n",
    "    #TODO:\n",
    "    \n",
    "    \n",
    "    return dj_dw,dj_db    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lecture, *gradient descent* was described as:\n",
    "\n",
    "$$\\begin{align*} \\text{repeat}&\\text{ until convergence:} \\; \\lbrace \\newline\n",
    "\\;  w &= w -  \\alpha \\frac{\\partial J(w,b)}{\\partial w} \\tag{3}  \\; \\newline \n",
    " b &= b -  \\alpha \\frac{\\partial J(w,b)}{\\partial b}  \\newline \\rbrace\n",
    "\\end{align*}$$\n",
    "where, parameters $w$, $b$ are updated simultaneously.  \n",
    "\n",
    "\n",
    "Here *simultaniously* means that you calculate the partial derivatives for all the parameters before updating any of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gradient_Descent(x, y , w_init, lr, iteration):\n",
    "\n",
    "    #For drawing figure, do not care\n",
    "    cost_history = []\n",
    "    w_history = []\n",
    "    #Start Here\n",
    "    w = w_init\n",
    "\n",
    "    \n",
    "    for num in range(iteration):\n",
    "\n",
    "        #TODO:\n",
    "        dj_dw, dj_db\n",
    "        \n",
    "\n",
    "        #For drawing figure, do not care\n",
    "        cost = Cost_function(x,y,w)\n",
    "        cost_history.append(cost)\n",
    "        w_history.append(w)\n",
    "        \n",
    "        if (num % 10 == 0):\n",
    "            print(f\"Iter:{num:4}, Cost : {cost:0.4e}, \"\n",
    "                  f\"dj_dw : {dj_dw:0.3e}, w : {w:0.3e}\")\n",
    "                  \n",
    "\n",
    "    return w,cost,w_history,cost_history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modulation Part\n",
    "lr : learning rate \\\n",
    "iteration : the total amount of trainig \\\n",
    "You can justify lr and iteration to see the ultimate effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\FDU\\Machine Learning\\tutoring\\Vector.ipynb 单元格 14\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m iteration  \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m w_new,cost_new,w_history,cost_history \u001b[39m=\u001b[39m Gradient_Descent(x_data,y_data,w_init,lr,iteration)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plot_gradient(x_data,y_data,w_history,cost_history)\n",
      "\u001b[1;32md:\\FDU\\Machine Learning\\tutoring\\Vector.ipynb 单元格 14\u001b[0m in \u001b[0;36mGradient_Descent\u001b[1;34m(x, y, w_init, lr, iteration)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     w_history\u001b[39m.\u001b[39mappend(w)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mif\u001b[39;00m (num \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIter:\u001b[39m\u001b[39m{\u001b[39;00mnum\u001b[39m:\u001b[39;00m\u001b[39m4\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, Cost : \u001b[39m\u001b[39m{\u001b[39;00mcost\u001b[39m:\u001b[39;00m\u001b[39m0.4e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdj_dw : \u001b[39m\u001b[39m{\u001b[39;00mdj_dw\u001b[39m:\u001b[39;00m\u001b[39m0.3e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, w : \u001b[39m\u001b[39m{\u001b[39;00mw\u001b[39m:\u001b[39;00m\u001b[39m0.3e\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/FDU/Machine%20Learning/tutoring/Vector.ipynb#X24sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mreturn\u001b[39;00m w,cost,w_history,cost_history\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "#Hyperparametres\n",
    "lr = 0.01\n",
    "iteration  = 100\n",
    "w_new,cost_new,w_history,cost_history = Gradient_Descent(x_data,y_data,w_init,lr,iteration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
